#!/usr/bin/env ruby

# Exit cleanly from an early interrupt
Signal.trap("INT") { exit 1 }

# Setup the bundled gems in our environment
require 'bundler/setup'

# Used for getting jobs from the queue and processing them
require_relative '../lib/ncbo_cron'
config_exists = File.exist?(File.expand_path('../../config/config.rb', __FILE__))
abort("Please create a config/config.rb file using the config/config.rb.sample as a template") unless config_exists
require_relative '../config/config'

# redis store for looking up queued jobs
require 'redis'

# Daemonize the process
require 'dante'

runner = Dante::Runner.new('ncbo_cron')
runner.description = "This will run a scheduled job for NCBO-related processing"

runner.with_options do |opts|
  opts.on("-P", "--pid FILE", String, "save PID in FILE when using -d option", "(default: ./bin/ncbo_cron.pid)") do |v|
    options[:pid_path] = File.expand_path(v)
  end
  opts.on("-h", "--redis-host HOST", String, "redis host (for shared locking)", "(default: localhost)") do |host|
    options[:redis_host] = host
  end
  opts.on("-p", "--redis-port PORT", Integer, "redis port (for shared locking)", "(default: 6379)") do |port|
    options[:redis_port] = port
  end
  opts.on("-m", "--minutes MIN", Integer, "minutes between process queue checks (override seconds)") do |m|
    options[:minutes_between] = m
  end
  opts.on("-s", "--seconds SEC", Integer, "seconds between process queue checks") do |s|
    options[:seconds_between] = s
  end
  opts.on("-c", "--pull-cron SCHED", String, "cron schedule for ontology pull") do |c|
    options[:cron_schedule] = c
  end
  opts.on("-l", "--log-level LEVEL", String, "set the log level (debug, info, error)", "(default: info)") do |c|
    options[:log_level] = c.to_sym
  end
  opts.on("--disable-processing", "disable ontology processing") do |v|
    options[:disable_processing] = v
  end
  opts.on("--disable-pull", "disable ontology pull") do |v|
    options[:disable_pull] = v
  end
  opts.on("--disable-flush", "disable flush archive class graphs") do |v|
    options[:disable_flush] = v
  end
  opts.on("-q", "--view-queue", "view queued jobs") do |v|
    options[:view_queue] = v
  end
  opts.on("-a", "--add-submission ID", String, "submission id to add to the queue") do |v|
    options[:queue_submission] = v
  end
  opts.on("--console", "REPL for working with scheduler") do |v|
    options[:console] = v
  end
  opts.on("-f","--flush-old-graphs", "Delete class graphs of archive submissions") do |c|
    options[:cron_flush] = c
  end
  
  
  # Logging
  require 'logger'
  log_dir = File.expand_path("../../logs", __FILE__)
  FileUtils.mkdir_p(log_dir)
  options[:log_path] ||= "#{log_dir}/scheduler.log"
  
  options[:pid_path] = File.expand_path("../ncbo_cron.pid", __FILE__)
  
  # Defaults
  options[:redis_host]    ||= "localhost"
  options[:redis_port]    ||= 6379
  options[:cron_schedule] ||= "00 18 * * 1-5"
  options[:cron_flush] ||= "00 23 * * 1-5"
  options[:log_level]     ||= :info
  options.delete(:host)
  options.delete(:port)
end

runner.execute do |opts|
  redis = Redis.new(host: opts[:redis_host], port: opts[:redis_port])
  
  puts "Running ncbo_cron with options:"
  pp opts
  
  # If we're viewing queued entries, show them and quit
  if opts[:view_queue]
    parser = NcboCron::Models::OntologySubmissionParser.new
    queued_items = parser.queued_items(redis).map {|a| {ontology: a[:key], actions: a[:actions]}}
    puts "\n\n"
    queued_items.empty? ? puts("Nothing queued") : pp(queued_items)
    exit
  end

  # Queue a provided submission, then exit
  if opts[:queue_submission]
    puts "\n\nQueueing submission: #{opts[:queue_submission]}"
    sub = LinkedData::Models::OntologySubmission.find(RDF::URI.new(opts[:queue_submission])).first
    abort("Error: Submission not found") unless sub
    parser = NcboCron::Models::OntologySubmissionParser.new
    parser.queue_submission(sub)
    exit
  end
  
  if opts[:console]
    require 'pry'; binding.pry(quiet: true)
    exit
  end
  
  # Redirect stdout, stderr
  log_file = File.new(opts[:log_path], "a")
  logger = Logger.new(log_file, shift_age = 'daily')
  $stderr = log_file
  $stdout = log_file
  log_levels = {
    fatal: Logger::FATAL,
    error: Logger::ERROR,
    warn:  Logger::WARN,
    info:  Logger::INFO,
    debug: Logger::DEBUG
  }
  logger.level = log_levels[opts[:log_level]]

  options = {
    logger: logger
  }.merge(opts)
  
  unless options[:disable_processing]
    parsing_thread = Thread.new do
      logger.debug "Setting up process queue check job"; logger.flush
      parse_options = options.dup
      parse_options.delete(:cron_schedule)
      parse_options[:job_name] = "ncbo_cron_parsing"
      NcboCron::Scheduler.scheduled_locking_job(parse_options) do
        logger.info "Starting ontology process queue check"; logger.flush
        parser = NcboCron::Models::OntologySubmissionParser.new
        parser.process_queue_submissions()
        logger.info "Finished ontology process queue check"; logger.flush
      end
    end
  end

  at_exit do
    if parsing_thread
      parsing_thread.kill
      parsing_thread.join
    end
  end

  unless options[:disable_pull]
    pull_thread = Thread.new do
      logger.debug "Setting up pull cron job"; logger.flush
      pull_options = options.dup
      pull_options.delete(:minutes_between)
      pull_options.delete(:seconds_between)
      pull_options[:job_name] = "pull_thread"
      pull_options[:scheduler_type] = :cron
      NcboCron::Scheduler.scheduled_locking_job(pull_options) do
        filename = File.basename(options[:log_path]).sub(/\.\w{1,4}$/, "")
        pull_log_path = options[:log_path].split("/")[0..-2].push("#{filename}-pull.log").join("/")
        pull_logger = Logger.new(pull_log_path, "a")
        logger.info "Starting ncbo pull"; logger.flush
        logger.info "Logging pull details to #{pull_log_path}"; logger.flush
        puller = NcboCron::Models::OntologyPull.new
        pulled_onts = puller.do_remote_ontology_pull(logger: pull_logger)
        logger.info "Finished ncbo pull"; logger.flush
        logger.info "Pull summary:\n#{pulled_onts.map {|o| o.id.to_s}}"
      end
    end
  end

  at_exit do
    if pull_thread
      pull_thread.kill
      pull_thread.join
    end
  end

  unless options[:disable_flush]
    flush_thread = Thread.new do
      logger.debug "Setting up the flush cron job"; logger.flush
      flush_options = options.dup
      flush_options.delete(:minutes_between)
      flush_options.delete(:seconds_between)
      flush_options[:job_name] = "flush_thread"
      flush_options[:scheduler_type] = :cron
      NcboCron::Scheduler.scheduled_locking_job(flush_options) do
        filename = File.basename(options[:log_path]).sub(/\.\w{1,4}$/, "")
        flush_log_path = options[:log_path].split("/")[0..-2].push("#{filename}-flush.log").join("/")
        flush_logger = Logger.new(flush_log_path, "a")
        logger.info "Starting ncbo flush"; logger.flush
        logger.info "Logging flush details to #{flush_log_path}"; logger.flush
        t0 = Time.now
        parser = NcboCron::Models::OntologySubmissionParser.new
        flush_onts = parser.process_flush_classes(logger)
        logger.info "Flushed #{flush_onts.length} submissions in #{Time.now - t0} sec."; logger.flush
        logger.info "Finished flush"; logger.flush
      end
    end
  end

  at_exit do
    if flush_thread
      flush_thread.kill
      flush_thread.join
    end
  end

  parsing_thread.join if parsing_thread
  pull_thread.join if pull_thread
  flush_thread.join if flush_thread
end
